{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T05:59:53.133262Z",
     "iopub.status.busy": "2021-06-26T05:59:53.132869Z",
     "iopub.status.idle": "2021-06-26T06:10:23.836864Z",
     "shell.execute_reply": "2021-06-26T06:10:23.835768Z",
     "shell.execute_reply.started": "2021-06-26T05:59:53.133183Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torch_geometric torch_sparse torch_scatter torch_spline_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:10:23.852426Z",
     "iopub.status.busy": "2021-06-26T06:10:23.851978Z",
     "iopub.status.idle": "2021-06-26T06:10:33.363920Z",
     "shell.execute_reply": "2021-06-26T06:10:33.362792Z",
     "shell.execute_reply.started": "2021-06-26T06:10:23.852397Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "\n",
    "import pickle\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from sklearn.metrics import accuracy_score,recall_score, average_precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:22.137832Z",
     "iopub.status.busy": "2021-06-26T06:44:22.137246Z",
     "iopub.status.idle": "2021-06-26T06:44:22.141728Z",
     "shell.execute_reply": "2021-06-26T06:44:22.141117Z",
     "shell.execute_reply.started": "2021-06-26T06:44:22.137801Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes = 5\n",
    "features = 26\n",
    "batch_size = 3\n",
    "seq_len = 10   # 序列的长度\n",
    "sequtienal = 10\n",
    "train_rate = 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:22.532706Z",
     "iopub.status.busy": "2021-06-26T06:44:22.532083Z",
     "iopub.status.idle": "2021-06-26T06:44:23.052326Z",
     "shell.execute_reply": "2021-06-26T06:44:23.051411Z",
     "shell.execute_reply.started": "2021-06-26T06:44:22.532671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "指标信息： (8640, 130)\n",
      "边集: torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"/kaggle/input/topomad/DatasetUpdate/MBD (1).csv\"\n",
    "TOPOLOGY = \"/kaggle/input/topomad/DatasetUpdate/MBD_topology.pk\"\n",
    "\n",
    "data = pd.read_csv(DATASET, header=[0,1])\n",
    "# preprocess\n",
    "labels = data['label']\n",
    "metric = data.drop(['date', 'label'], axis = 1)\n",
    "metric.columns.names = ['host','metric']\n",
    "tempm = metric.swaplevel('metric','host',axis=1).stack()\n",
    "\n",
    "tempm = (tempm-tempm.mean())/(tempm.std())\n",
    "metric = tempm.unstack().swaplevel('metric','host',axis=1).stack().unstack()\n",
    "\n",
    "with open(TOPOLOGY, 'rb') as f:\n",
    "    edge_tensor = pickle.load(f)\n",
    "    \n",
    "data = metric.values\n",
    "edge_tensor = np.array(edge_tensor)\n",
    "edge_tensor = torch.LongTensor(edge_tensor)\n",
    "print(\"指标信息：\",data.shape)\n",
    "print(\"边集:\",edge_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 整理数据格式\n",
    "由于我们的模型输入必须是一个序列，所以我们必须把数据整理为`(数据总数，序列长度，实际数据)`的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:23.102585Z",
     "iopub.status.busy": "2021-06-26T06:44:23.102272Z",
     "iopub.status.idle": "2021-06-26T06:44:23.154570Z",
     "shell.execute_reply": "2021-06-26T06:44:23.153721Z",
     "shell.execute_reply.started": "2021-06-26T06:44:23.102558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 5, 26)\n",
      "序列数据形状: (8631, 10, 5, 26)\n"
     ]
    }
   ],
   "source": [
    "data_reshape = data.reshape((-1,nodes,features))\n",
    "print(data_reshape.shape)\n",
    "def sequence_data_preparation(seq_len, data):\n",
    "    X = []\n",
    "    for i in range(data.shape[0] - int(seq_len - 1) ):\n",
    "        X.append(data[i : i + seq_len, ...])\n",
    "    return np.array(X)\n",
    "\n",
    "data_sequence  = sequence_data_preparation(seq_len, data_reshape)\n",
    "print(\"序列数据形状:\",data_sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 划分数据集\n",
    "- 数据划分按照`2/3训练集`和`1/3测试集`进行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:23.830313Z",
     "iopub.status.busy": "2021-06-26T06:44:23.829960Z",
     "iopub.status.idle": "2021-06-26T06:44:23.901962Z",
     "shell.execute_reply": "2021-06-26T06:44:23.900831Z",
     "shell.execute_reply.started": "2021-06-26T06:44:23.830281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (5782, 10, 5, 26)\n",
      "Test data:  (2849, 10, 5, 26)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data, train_portion):\n",
    "    time_len = data.shape[0]\n",
    "    train_size = int(time_len * train_portion)\n",
    "    train_data = np.array(data[:train_size,...])\n",
    "    test_data = np.array(data[train_size:,...])\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = train_test_split(data_sequence,train_rate)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)\n",
    "train_data_tensor = torch.Tensor(train_data)\n",
    "test_data_tensor = torch.Tensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:24.436961Z",
     "iopub.status.busy": "2021-06-26T06:44:24.436622Z",
     "iopub.status.idle": "2021-06-26T06:44:24.446584Z",
     "shell.execute_reply": "2021-06-26T06:44:24.445690Z",
     "shell.execute_reply.started": "2021-06-26T06:44:24.436933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丢弃训练样本数量: 1\n",
      "丢弃测试样本数量: 2\n"
     ]
    }
   ],
   "source": [
    "train_data_tensor_batch = torch.utils.data.DataLoader(train_data_tensor,batch_size=batch_size,drop_last=True,shuffle=True)\n",
    "test_data_tensor_batch = torch.utils.data.DataLoader(test_data_tensor,batch_size=batch_size,drop_last=True)\n",
    "train_size = int(train_data_tensor.shape[0] / batch_size)\n",
    "test_size = int(test_data_tensor.shape[0] / batch_size)\n",
    "print(\"丢弃训练样本数量:\",train_data_tensor.shape[0] - train_size * batch_size)\n",
    "print(\"丢弃测试样本数量:\",test_data_tensor.shape[0] - test_size * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 创建TopoMAD模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:25.416983Z",
     "iopub.status.busy": "2021-06-26T06:44:25.416349Z",
     "iopub.status.idle": "2021-06-26T06:44:25.430026Z",
     "shell.execute_reply": "2021-06-26T06:44:25.429306Z",
     "shell.execute_reply.started": "2021-06-26T06:44:25.416929Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphLSTMCell(torch.nn.Module):\n",
    "    def __init__(self,batch_size,edge_tensor,nodes,input_size,lstm_output):\n",
    "        \"\"\"\n",
    "        NOTE: \n",
    "            GraphLSTMCell为GraphLSTM中的一个单元模块，简单来说GraphLSTMCell仅仅在LSTMCell的全链接网络中，加入GNN来提取特征。\n",
    "            模型输入尺寸：[batch, nodes, input_size]\n",
    "            模型输出尺寸：[batch, nodes * lstm_output]\n",
    "            \n",
    "        arg:\n",
    "            batch_size: 数据的批处理量\n",
    "            edge_tensor：数据的边集\n",
    "            nodes: 节点数量\n",
    "            input_isze: 每个节点特征的数量\n",
    "            lstm_output: 提取后每个节点的特征数量\n",
    "        \n",
    "        return:\n",
    "            h: GraphLSTM的输出\n",
    "            c: GraphLSTM的单元状态\n",
    "        \"\"\"\n",
    "        super(GraphLSTMCell,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.nodes = nodes\n",
    "        self.input_size = input_size\n",
    "        self.edge_tensor = edge_tensor\n",
    "        self.lstm_output = lstm_output\n",
    "        \n",
    "        gcn_input = input_size + lstm_output\n",
    "        gcn_output = int(lstm_output * 1.3)\n",
    "        lstm_input_size = gcn_output * nodes\n",
    "        lstm_output_flatten = lstm_output * nodes\n",
    "\n",
    "        self.gcn = GCNConv(gcn_input,gcn_output)\n",
    "        self.h = torch.zeros(batch_size, lstm_output_flatten)\n",
    "        self.c = torch.zeros(batch_size, lstm_output_flatten)\n",
    "        self.cell = nn.LSTMCell(lstm_input_size, lstm_output_flatten)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(lstm_output_flatten,lstm_output_flatten)\n",
    "    \n",
    "    def get_init(self):\n",
    "        return self.h, self.c\n",
    "    \n",
    "    def cat(self,xt,h):\n",
    "        return torch.cat([xt,h],dim=2)\n",
    "    \n",
    "    def forward(self, xt, h, c):\n",
    "        h = h.reshape(self.batch_size,self.nodes,-1)\n",
    "        xt = self.cat(xt,h)\n",
    "        xt = self.gcn(xt,self.edge_tensor)\n",
    "        xt = xt.view(self.batch_size,-1)\n",
    "        h = h.view(self.batch_size,-1)\n",
    "        h, c = self.cell(xt, (h, c))\n",
    "        h = self.dropout(h)\n",
    "        h = self.dense(h)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:26.236467Z",
     "iopub.status.busy": "2021-06-26T06:44:26.235948Z",
     "iopub.status.idle": "2021-06-26T06:44:26.243544Z",
     "shell.execute_reply": "2021-06-26T06:44:26.242681Z",
     "shell.execute_reply.started": "2021-06-26T06:44:26.236436Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphLSTM(GraphLSTMCell):\n",
    "    def __init__(self,seq_len,*arg):\n",
    "        \"\"\"\n",
    "        NOTE: \n",
    "            由于很多属性可以通用，所以GraphLSTM继承至GraphLSTMCell\n",
    "            模型输入尺寸：[seq_len, batch, nodes, input_size]\n",
    "            模型输出尺寸：[seq_len, batch, nodes * lstm_output]\n",
    "\n",
    "        arg:\n",
    "            seq_len： 序列数据的长度\n",
    "\n",
    "        return:\n",
    "            h: GraphLSTMCell的最后输出\n",
    "            c: GraphLSTMCell的最后状态\n",
    "            xt: GraphLSTM 中最后一个数据\n",
    "            h_list: GraphLSTMCell的输出集合\n",
    "        \"\"\"\n",
    "        super(GraphLSTM, self).__init__(*arg)\n",
    "        self.seq_len = seq_len\n",
    "        self.graph_lstm_cell = GraphLSTMCell(*arg)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h, c = self.graph_lstm_cell.get_init()\n",
    "        h_list = []\n",
    "        for xt in x:\n",
    "            h, c = self.graph_lstm_cell(xt,h,c)\n",
    "            h_list.append(h)\n",
    "        h_list = torch.stack(h_list,1)\n",
    "        h_list = h_list.view(self.batch_size,self.seq_len,self.nodes,-1)\n",
    "        h_list = h_list.transpose(0,1)\n",
    "        return h, c, xt, h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:26.617673Z",
     "iopub.status.busy": "2021-06-26T06:44:26.617262Z",
     "iopub.status.idle": "2021-06-26T06:44:26.623011Z",
     "shell.execute_reply": "2021-06-26T06:44:26.622301Z",
     "shell.execute_reply.started": "2021-06-26T06:44:26.617638Z"
    }
   },
   "outputs": [],
   "source": [
    "class CoderBase(torch.nn.Module):\n",
    "    def __init__(self,batch_size,input_size,output_size):\n",
    "        \"\"\"\n",
    "        NOTE: 用来实例化Encoder和Decoder\n",
    "\n",
    "        arg:\n",
    "            batch_size: 批处理量\n",
    "            input_size: 输入尺寸\n",
    "            output_size: 输出尺寸\n",
    "        \"\"\"\n",
    "        super(CoderBase, self).__init__()\n",
    "        self.encoder_log_var = nn.Linear(input_size,output_size)\n",
    "        self.encoder_mu = nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(x)\n",
    "        return self.encoder_mu(h), self.encoder_log_var(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:27.036493Z",
     "iopub.status.busy": "2021-06-26T06:44:27.036006Z",
     "iopub.status.idle": "2021-06-26T06:44:27.046498Z",
     "shell.execute_reply": "2021-06-26T06:44:27.045681Z",
     "shell.execute_reply.started": "2021-06-26T06:44:27.036449Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphLSTM_Decoder(GraphLSTMCell):\n",
    "    def __init__(self,decoder,seq_len,*arg):\n",
    "        \"\"\"\n",
    "        NOTE: \n",
    "            继承于GraphLSTMCell，在GraphLSTMCell之间加上了Decoder和处理序列数据\n",
    "            \n",
    "        arg:\n",
    "            decoder: 解码器\n",
    "            seq_len: 序列长度\n",
    "            \n",
    "        return:\n",
    "            reconst_mu_list: 重构样本的mu\n",
    "            reonst_log_var_list: 重构样本的log_var\n",
    "            origin: 原始数据\n",
    "        \"\"\"\n",
    "        super().__init__(*arg)\n",
    "        self.decoder = decoder\n",
    "        self.seq_len = seq_len\n",
    "        self.graph_lstm_cell = GraphLSTMCell(*arg)\n",
    "        \n",
    "    def return_tensor(self,reconst_mu_list,reonst_log_var_list,origin):\n",
    "        tran_view = (self.batch_size, self.seq_len,self.nodes, -1)\n",
    "        \n",
    "        reconst_mu_list = torch.stack(reconst_mu_list).transpose(0,1)\n",
    "        reconst_mu_list = reconst_mu_list.view(*tran_view)\n",
    "        reonst_log_var_list = torch.stack(reonst_log_var_list,0).transpose(0,1)\n",
    "        reonst_log_var_list = reonst_log_var_list.view(*tran_view)\n",
    "        origin = torch.stack(origin,0).transpose(0,1)\n",
    "        origin = origin.view(*tran_view)\n",
    "        return reconst_mu_list,reonst_log_var_list,origin\n",
    "        \n",
    "    def forward(self, x, c,reconst_mu,focing,reconst_mu_list, reonst_log_var_list, origin):\n",
    "        reconst_h, _ = self.graph_lstm_cell.get_init()\n",
    "        \n",
    "        for xt in torch.flip(x[:-1],dims=[0]):\n",
    "            xxt = xt if focing else reconst_mu.view(self.batch_size,self.nodes,-1)\n",
    "            reconst_h, c = self.graph_lstm_cell(xxt,reconst_h, c)\n",
    "            reconst_mu, reonst_log_var = self.decoder(reconst_h)\n",
    "    \n",
    "            reconst_mu_list.append(reconst_mu)\n",
    "            reonst_log_var_list.append(reonst_log_var)\n",
    "            origin.append(xt)\n",
    "\n",
    "        return self.return_tensor(reconst_mu_list,reonst_log_var_list,origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:27.681686Z",
     "iopub.status.busy": "2021-06-26T06:44:27.681343Z",
     "iopub.status.idle": "2021-06-26T06:44:27.692872Z",
     "shell.execute_reply": "2021-06-26T06:44:27.692120Z",
     "shell.execute_reply.started": "2021-06-26T06:44:27.681656Z"
    }
   },
   "outputs": [],
   "source": [
    "class TopoMAD(torch.nn.Module):\n",
    "    def __init__(self,seq_len,batch_size,edge_tensor,nodes,input_size):\n",
    "        \"\"\"\n",
    "        NOTE: 论文模型\n",
    "        \n",
    "        arg:\n",
    "            seq_len: 序列长度\n",
    "            batch_size: 批处理量\n",
    "            edge_tensor: 边集信息\n",
    "            nodes: 节点数量\n",
    "            input_size: 单个节点的输入数量\n",
    "            \n",
    "        attr:\n",
    "            lstm_01_output: 经过GraphLSTM之后每个节点的特征数量\n",
    "            latent_size: 所有节点潜变量总共的数量\n",
    "            foring: 是否有教师进行指导\n",
    "        \"\"\"\n",
    "        super(TopoMAD, self).__init__()\n",
    "        arg = (seq_len,batch_size,edge_tensor,nodes,input_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.nodes = nodes\n",
    "        \n",
    "        lstm_01_output = 15\n",
    "        self.graph_01 = GraphLSTM(*arg,lstm_01_output)\n",
    "        \n",
    "        latent_size = 25\n",
    "        self.encoder = CoderBase(batch_size,lstm_01_output * self.nodes, latent_size)\n",
    "        \n",
    "        hidden_size = lstm_01_output * self.nodes\n",
    "        self.z_mlp = nn.Linear(latent_size,hidden_size)\n",
    "        self.decoder = CoderBase(batch_size,hidden_size, self.nodes * features)  # 60 -> 5 * 26\n",
    "        self.GraphLSTM_Decoder = GraphLSTM_Decoder(self.decoder,*arg,lstm_01_output)\n",
    "        self.forcing = False\n",
    " \n",
    "    def reparamterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h, c, xt, h_list = self.graph_01(x)  # H   [10,3,5,26] -> [3, 5 * 20]\n",
    "        mu, log_var = self.encoder(h)        # mu: [3,100] -> [3,15]\n",
    "        z = self.reparamterize(mu, log_var)  # z:  [3,15]\n",
    "        z_point = self.z_mlp(z)              #     [3,15] -> [3,100]\n",
    "        reconst_mu, reonst_log_var = self.decoder(z_point)  # [3,100] -> [3, 130]\n",
    "        reconst_mu_list, reonst_log_var_list, origin = [reconst_mu], [reonst_log_var], [xt]\n",
    "        \n",
    "        reconst_mu_list, reonst_log_var_list, origin = self.GraphLSTM_Decoder(x,c,reconst_mu,self.forcing,\n",
    "                                                                              reconst_mu_list, reonst_log_var_list, origin)\n",
    "        mu = mu.view(self.batch_size,self.nodes,-1)\n",
    "        log_var = log_var.view(self.batch_size,self.nodes,-1)\n",
    "        \n",
    "        return reconst_mu_list,origin, mu, log_var, reonst_log_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:28.180610Z",
     "iopub.status.busy": "2021-06-26T06:44:28.180081Z",
     "iopub.status.idle": "2021-06-26T06:44:28.187277Z",
     "shell.execute_reply": "2021-06-26T06:44:28.186354Z",
     "shell.execute_reply.started": "2021-06-26T06:44:28.180550Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(preds, origin, mu, logvar, output_logvar):\n",
    "    recon_loss = 0.5 * torch.mean(torch.sum(torch.div((preds - origin) ** 2, output_logvar.exp()) + output_logvar, (1,2,3)))\n",
    "    s = torch.sum(1 + logvar - mu**2 - logvar.exp(),(1,2))\n",
    "    kl_loss = -0.5 * torch.mean(s)\n",
    "    total_loss = recon_loss + kl_loss\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "def is_anomaly(preds, origin, output_logvar): \n",
    "    div = torch.div((preds - origin) ** 2, output_logvar.exp())\n",
    "    s = torch.sum( div + output_logvar, (2,3))\n",
    "    recon_loss = 0.5 * torch.mean(s,1)\n",
    "    return recon_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:29.261376Z",
     "iopub.status.busy": "2021-06-26T06:44:29.261003Z",
     "iopub.status.idle": "2021-06-26T06:44:29.272007Z",
     "shell.execute_reply": "2021-06-26T06:44:29.271063Z",
     "shell.execute_reply.started": "2021-06-26T06:44:29.261343Z"
    }
   },
   "outputs": [],
   "source": [
    "# seq_len,batch_size,edge_tensor,nodes,input_size,lstm_output\n",
    "topomad = TopoMAD(seq_len,batch_size,edge_tensor,nodes,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:44:29.701120Z",
     "iopub.status.busy": "2021-06-26T06:44:29.700628Z",
     "iopub.status.idle": "2021-06-26T06:44:29.704673Z",
     "shell.execute_reply": "2021-06-26T06:44:29.703849Z",
     "shell.execute_reply.started": "2021-06-26T06:44:29.701091Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_random_bool(p = 0.8):\n",
    "    print(p)\n",
    "    random_bool = np.random.random() > p\n",
    "    print(random_bool)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:45:34.556625Z",
     "iopub.status.busy": "2021-06-26T06:45:34.556092Z",
     "iopub.status.idle": "2021-06-26T06:45:34.561226Z",
     "shell.execute_reply": "2021-06-26T06:45:34.560572Z",
     "shell.execute_reply.started": "2021-06-26T06:45:34.556571Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(topomad.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T06:45:34.998394Z",
     "iopub.status.busy": "2021-06-26T06:45:34.997948Z",
     "iopub.status.idle": "2021-06-26T07:56:43.901492Z",
     "shell.execute_reply": "2021-06-26T07:56:43.900167Z",
     "shell.execute_reply.started": "2021-06-26T06:45:34.998365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "False\n",
      " Epoch: 1, Process: [1920/1927], kl_div: 13.6144, reconst_loss: -560.8743\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1593219872939644\n",
      "0.04\n",
      "True\n",
      " Epoch: 2, Process: [1920/1927], kl_div: 17.1166, reconst_loss: -800.24376\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1532206140148239\n",
      "0.06\n",
      "True\n",
      " Epoch: 3, Process: [1920/1927], kl_div: 16.6677, reconst_loss: -791.08045\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.15942749020530572\n",
      "0.08\n",
      "True\n",
      " Epoch: 4, Process: [1920/1927], kl_div: 19.6603, reconst_loss: -1062.7188\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1644103912944591\n",
      "0.1\n",
      "True\n",
      " Epoch: 5, Process: [1920/1927], kl_div: 24.4093, reconst_loss: -1549.2570\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1635053273301464\n",
      "0.12\n",
      "True\n",
      " Epoch: 6, Process: [1920/1927], kl_div: 23.2645, reconst_loss: -1179.4366\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16867497422895644\n",
      "0.14\n",
      "True\n",
      " Epoch: 7, Process: [1920/1927], kl_div: 24.5066, reconst_loss: -1513.9154\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16263232088962537\n",
      "0.16\n",
      "True\n",
      " Epoch: 8, Process: [1920/1927], kl_div: 18.8099, reconst_loss: -878.07549\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16418738869291877\n",
      "0.18\n",
      "True\n",
      " Epoch: 9, Process: [1920/1927], kl_div: 24.1990, reconst_loss: -1396.7744\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16047024571521426\n",
      "0.2\n",
      "True\n",
      " Epoch: 10, Process: [1920/1927], kl_div: 18.8889, reconst_loss: -956.85167\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16599398584944297\n",
      "0.22\n",
      "True\n",
      " Epoch: 11, Process: [1920/1927], kl_div: 23.8098, reconst_loss: -1377.8981\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1676784719816256\n",
      "0.24\n",
      "True\n",
      " Epoch: 12, Process: [1920/1927], kl_div: 25.7717, reconst_loss: -878.75050\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.16573922466964786\n",
      "0.26\n",
      "True\n",
      " Epoch: 13, Process: [1920/1927], kl_div: 20.6761, reconst_loss: -1318.6938\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.17114859467060894\n",
      "0.28\n",
      "True\n",
      " Epoch: 14, Process: [1920/1927], kl_div: 19.5522, reconst_loss: -1442.8735\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.18010041239617713\n",
      "0.3\n",
      "True\n",
      " Epoch: 15, Process: [1920/1927], kl_div: 21.0438, reconst_loss: -1531.9194\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.1769035579542394\n",
      "0.32\n",
      "False\n",
      " Epoch: 16, Process: [1920/1927], kl_div: 27.1027, reconst_loss: -1682.0079\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.2029027225036218\n",
      "0.34\n",
      "True\n",
      " Epoch: 17, Process: [1920/1927], kl_div: 30.0979, reconst_loss: -2189.0120\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.20528345389251815\n",
      "0.36\n",
      "True\n",
      " Epoch: 18, Process: [1920/1927], kl_div: 24.2002, reconst_loss: -1741.5531\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.21385387854207874\n",
      "0.38\n",
      "False\n",
      " Epoch: 19, Process: [1920/1927], kl_div: 20.0476, reconst_loss: -1329.3926\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.21978610776810253\n",
      "0.4\n",
      "True\n",
      " Epoch: 20, Process: [1920/1927], kl_div: 23.6523, reconst_loss: -1088.0524\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.24811262101638376\n",
      "0.42\n",
      "False\n",
      " Epoch: 21, Process: [1920/1927], kl_div: 23.7288, reconst_loss: -1346.3158\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.25189687501507035\n",
      "0.44\n",
      "False\n",
      " Epoch: 22, Process: [1920/1927], kl_div: 24.2357, reconst_loss: -1711.3712\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.2765872709402567\n",
      "0.46\n",
      "False\n",
      " Epoch: 23, Process: [1920/1927], kl_div: 27.9460, reconst_loss: -2071.2278\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.2963691350907838\n",
      "0.48\n",
      "True\n",
      " Epoch: 24, Process: [1920/1927], kl_div: 18.6545, reconst_loss: -1454.9102\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.29977479048160127\n",
      "0.5\n",
      "True\n",
      " Epoch: 25, Process: [1920/1927], kl_div: 27.8249, reconst_loss: -2121.6731\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3272906694907254\n",
      "0.52\n",
      "False\n",
      " Epoch: 26, Process: [1920/1927], kl_div: 23.5207, reconst_loss: -1583.1635\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3320080073218793\n",
      "0.54\n",
      "True\n",
      " Epoch: 27, Process: [1920/1927], kl_div: 25.5358, reconst_loss: -1710.9912\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.33952181310361046\n",
      "0.56\n",
      "True\n",
      " Epoch: 28, Process: [1920/1927], kl_div: 20.9785, reconst_loss: -1069.8490\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.35618762177430113\n",
      "0.58\n",
      "False\n",
      " Epoch: 29, Process: [1920/1927], kl_div: 21.3283, reconst_loss: -1200.3824\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3984605118598417\n",
      "0.6\n",
      "False\n",
      " Epoch: 30, Process: [1920/1927], kl_div: 23.6947, reconst_loss: -1865.1855\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.37807899655124916\n",
      "0.62\n",
      "False\n",
      " Epoch: 31, Process: [1920/1927], kl_div: 28.2331, reconst_loss: -1772.5590\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3834647588788223\n",
      "0.64\n",
      "False\n",
      " Epoch: 32, Process: [1920/1927], kl_div: 24.9314, reconst_loss: -1667.3677\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.39934385524520183\n",
      "0.66\n",
      "False\n",
      " Epoch: 33, Process: [1920/1927], kl_div: 28.9642, reconst_loss: -1628.3527\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3968485483301242\n",
      "0.68\n",
      "True\n",
      " Epoch: 34, Process: [1920/1927], kl_div: 24.5156, reconst_loss: -1764.8217\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.40099933858737746\n",
      "0.7\n",
      "False\n",
      " Epoch: 35, Process: [1920/1927], kl_div: 23.9750, reconst_loss: -1541.6104\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.39758278152131077\n",
      "0.72\n",
      "True\n",
      " Epoch: 36, Process: [1920/1927], kl_div: 26.7868, reconst_loss: -1843.5541\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.4017685794143828\n",
      "0.74\n",
      "False\n",
      " Epoch: 37, Process: [1920/1927], kl_div: 39.4389, reconst_loss: -3040.9355\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.4006147861635824\n",
      "0.76\n",
      "False\n",
      " Epoch: 38, Process: [1920/1927], kl_div: 23.4885, reconst_loss: -1440.1455\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.42405812971412393\n",
      "0.78\n",
      "True\n",
      " Epoch: 39, Process: [1920/1927], kl_div: 25.2741, reconst_loss: -1566.3643\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.4428594608524\n",
      "0.8\n",
      "False\n",
      " Epoch: 40, Process: [1920/1927], kl_div: 21.5145, reconst_loss: -1453.6802\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.43250664390952137\n",
      "0.82\n",
      "False\n",
      " Epoch: 41, Process: [1920/1927], kl_div: 31.7141, reconst_loss: -2181.2866\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.4326183129127697\n",
      "0.84\n",
      "False\n",
      " Epoch: 42, Process: [1920/1927], kl_div: 22.0690, reconst_loss: -1942.7012\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.40631610641615246\n",
      "0.86\n",
      "True\n",
      " Epoch: 43, Process: [1920/1927], kl_div: 29.1284, reconst_loss: -1226.6855\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.39973966859120985\n",
      "0.88\n",
      "False\n",
      " Epoch: 44, Process: [1920/1927], kl_div: 28.5033, reconst_loss: -2606.5579\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.3838010863459096\n",
      "0.9\n",
      "False\n",
      " Epoch: 45, Process: [1920/1927], kl_div: 25.6996, reconst_loss: -2227.6562\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.41449044200559726\n",
      "0.92\n",
      "False\n",
      " Epoch: 46, Process: [1920/1927], kl_div: 28.5634, reconst_loss: -1534.3483\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.43489537734105976\n",
      "0.94\n",
      "False\n",
      " Epoch: 47, Process: [1920/1927], kl_div: 27.9015, reconst_loss: -1910.0010\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.43142728206179193\n",
      "0.96\n",
      "False\n",
      " Epoch: 48, Process: [1920/1927], kl_div: 31.6502, reconst_loss: -2116.2395\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.442797359722366\n",
      "0.98\n",
      "False\n",
      " Epoch: 49, Process: [1920/1927], kl_div: 24.0853, reconst_loss: -1716.2939\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.45919592024238487\n",
      "1.0\n",
      "False\n",
      " Epoch: 50, Process: [1920/1927], kl_div: 27.1259, reconst_loss: -1709.9723\n",
      " Test Process: [900/949]\n",
      "Test AP: 0.41760636835063986\n",
      "CPU times: user 1h 49min 6s, sys: 28.1 s, total: 1h 49min 34s\n",
      "Wall time: 1h 11min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch += 1\n",
    "    topomad.forcing = return_random_bool(p = epoch / num_epochs)\n",
    "#     topomad.focing = True\n",
    "    topomad.train()\n",
    "    for id_,xt in enumerate(train_data_tensor_batch):\n",
    "        xt = xt.transpose(0,1)  # 10, 3, 5, 26\n",
    "        reconst_mu,origin, mu, log_var, reonst_log_var_list = topomad(xt)\n",
    "        total_loss, recon_loss, kl_loss = loss_function(reconst_mu,origin, mu, log_var, reonst_log_var_list)\n",
    "        if id_ % 30 == 0:\n",
    "            print(\"\\r\",\"Epoch: {}, Process: [{}/{}], kl_div: {:.4f}, reconst_loss: {:.4f}\".format(epoch,id_,train_size,kl_loss,recon_loss),end=\"\",flush=True)\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 测试\n",
    "    print()\n",
    "    topomad.forcing = False\n",
    "    topomad.eval()\n",
    "    pred_result = []\n",
    "    for id_,x in enumerate(test_data_tensor_batch):\n",
    "        with torch.no_grad():\n",
    "            x = x.transpose(0,1)\n",
    "            reconst_mu,origin, mu, log_var, reonst_log_var_list = topomad(x)\n",
    "            t = is_anomaly(reconst_mu, origin, reonst_log_var_list)\n",
    "            pred_result.append(t.detach().numpy())\n",
    "            if id_ % 50 == 0:\n",
    "                print(\"\\r\",\"Test Process: [{}/{}]\".format(id_,test_size),end=\"\",flush=True)\n",
    "\n",
    "    score_array = np.hstack(pred_result)\n",
    "    n = score_array.shape[0]\n",
    "    labels_array = labels.values.flatten()\n",
    "    test_labels = labels_array[:-9][-n:]\n",
    "    ap = average_precision_score(test_labels,score_array)\n",
    "    print()\n",
    "    print(\"Test AP:\",ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-26T08:13:52.063521Z",
     "iopub.status.busy": "2021-06-26T08:13:52.063046Z",
     "iopub.status.idle": "2021-06-26T08:13:52.086306Z",
     "shell.execute_reply": "2021-06-26T08:13:52.085371Z",
     "shell.execute_reply.started": "2021-06-26T08:13:52.063472Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(topomad,\"/kaggle/topomad.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
